{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPHh44X3BegGmpbNzkvZtYt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avyukthinna/ML_Lab/blob/main/1BM22CS060_BoostingEnsemble.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueJCs5JOoN_h"
      },
      "outputs": [],
      "source": [
        "# BOOSTING ENSEMBLE\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load your dataset from the local path\n",
        "df = pd.read_csv(\"/content/data.csv\")\n",
        "\n",
        "# Drop any unnamed columns (like 'Unnamed: 32')\n",
        "df.drop(columns=[col for col in df.columns if \"Unnamed\" in col], inplace=True)\n",
        "\n",
        "# Encode labels: M = 1 (Malignant), B = -1 (Benign)\n",
        "df['diagnosis'] = df['diagnosis'].map({'M' : 1, 'B': -1})\n",
        "\n",
        "# Drop ID column if present\n",
        "if 'id' in df.columns:\n",
        "    df.drop(columns=['id'], inplace=True)\n",
        "\n",
        "# Features and labels\n",
        "X = df.drop(['diagnosis'], axis=1).values\n",
        "y = df['diagnosis'].values\n",
        "\n",
        "# Normalize features\n",
        "X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
        "\n",
        "# Split dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Decision Stump class\n",
        "class DecisionStump:\n",
        "    def __init__(self):\n",
        "        self.feature_index = None\n",
        "        self.threshold = None\n",
        "        self.polarity = 1\n",
        "        self.alpha = None\n",
        "\n",
        "    def predict(self, X):\n",
        "        n = X.shape[0]\n",
        "        predictions = np.ones(n)\n",
        "        feature_values = X[:, self.feature_index]\n",
        "        if self.polarity == 1:\n",
        "            predictions[feature_values < self.threshold] = -1\n",
        "        else:\n",
        "            predictions[feature_values > self.threshold] = -1\n",
        "        return predictions\n",
        "\n",
        "# AdaBoost class\n",
        "class AdaBoost:\n",
        "    def __init__(self, n_clf=10):\n",
        "        self.n_clf = n_clf\n",
        "        self.clfs = []\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        n_samples, n_features = X.shape\n",
        "        weights = np.ones(n_samples) / n_samples\n",
        "\n",
        "        for _ in range(self.n_clf):\n",
        "            clf = DecisionStump()\n",
        "            min_error = float('inf')\n",
        "\n",
        "            for feature_i in range(n_features):\n",
        "                feature_values = X[:, feature_i]\n",
        "                thresholds = np.unique(feature_values)\n",
        "                for threshold in thresholds:\n",
        "                    for polarity in [1, -1]:\n",
        "                        predictions = np.ones(n_samples)\n",
        "                        if polarity == 1:\n",
        "                            predictions[feature_values < threshold] = -1\n",
        "                        else:\n",
        "                            predictions[feature_values > threshold] = -1\n",
        "\n",
        "                        error = np.sum(weights[y != predictions])\n",
        "\n",
        "                        if error < min_error:\n",
        "                            clf.polarity = polarity\n",
        "                            clf.threshold = threshold\n",
        "                            clf.feature_index = feature_i\n",
        "                            min_error = error\n",
        "\n",
        "            EPS = 1e-10\n",
        "            clf.alpha = 0.5 * np.log((1 - min_error) / (min_error + EPS))\n",
        "            predictions = clf.predict(X)\n",
        "            weights *= np.exp(-clf.alpha * y * predictions)\n",
        "            weights /= np.sum(weights)\n",
        "            self.clfs.append(clf)\n",
        "\n",
        "    def predict(self, X):\n",
        "        clf_preds = [clf.alpha * clf.predict(X) for clf in self.clfs]\n",
        "        y_pred = np.sum(clf_preds, axis=0)\n",
        "        return np.sign(y_pred)\n",
        "\n",
        "# Train and evaluate\n",
        "model = AdaBoost(n_clf=20)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = np.mean(y_pred == y_test)\n",
        "print(f\"\\nTest Accuracy with 20 classifiers: {accuracy:.4f}\")\n",
        "\n",
        "# Print predictions and actual labels\n",
        "print(\"\\nPredicted labels for test set:\")\n",
        "print(y_pred)\n",
        "\n",
        "print(\"\\nActual labels for test set:\")\n",
        "print(y_test)\n",
        "\n",
        "# Plot accuracy vs. number of classifiers\n",
        "accuracies = []\n",
        "for n in range(1, 31):\n",
        "    model = AdaBoost(n_clf=n)\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    acc = np.mean(y_pred == y_test)\n",
        "    accuracies.append(acc)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(range(1, 31), accuracies, marker='o')\n",
        "plt.title('AdaBoost Accuracy vs Number of Weak Classifiers')\n",
        "plt.xlabel('Number of Weak Classifiers')\n",
        "plt.ylabel('Test Accuracy')\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ]
}